## 2.2. 텐서의 특징

파이토치에서 연산 대상 데이터는 모두 Tensor라고 하는 파이토치 고유의 형식으로 돼 있어야 한다.

cf) 0계, 1계, 2계 텐서
- 0계 텐서: 스칼라
- 1계 텐서: 벡터
- 2계 텐서: 행렬
이라고 부름

<br>

| 텐서 함수/속성 | 설명 |
|--------------|------|
| `torch.tensor()` | - 텐서를 만들고 float32 형식으로 만들어줄 것 -> 아니면 에러 발생함<br>- 예외) `nn.CrossEntropyLoss`, `nn.NLLLoss`는 정수 타입(int64)을 사용함 |
| `shape` | - 텐서의 크기를 나타냄 (numpy의 shape와 동일) |
| `dtype` | - 텐서의 데이터 타입을 나타냄 (torch.float32, torch.int64 등) |
| `data` | - 텐서의 수치를 나타냄 (ex. tensor([1.]))<br>- 값만 복사하고 싶은 경우 `data.copy()`를 사용<br>- 원본 데이터에 영향을 줄 수 있으므로 현재는 `detach()`를 권장함 |
| `torch.manual_seed()` | - 난수 생성 시 시드를 고정해줌. 실무에서 보다는 학습환경을 맞추기 위해 사용<br>- 학습 환경을 맞추기 위해 사용 |
| `torch.ones()` | - 1로 채워진 텐서를 만들어줌 |
| `torch.randn()` | - 표준 정규 분포를 따르는 난수를 만들어줌 |
| `torch.view()` | - 텐서의 계수를 변환해줌. (numpy의 reshape와 동일)<br>- 이때 마지막에 -1을 넣으면 나머지 계수를 자동으로 계산해줌.<br>Ex. r.view(1, -1) => 1행에 나머지 계수를 자동으로 계산해줌. (곱셈식으로 생각하면 쉬움) |
| `torch.requires_grad` | - `True`로 설정하면 텐서의 연산 과정을 기록해줌 |
| `torch.device()` | - 텐서의 위치(gpu, cpu)를 지정해줌.<br>- 주로 딥러닝 학습 시 gpu를 사용하므로 딥러닝 학습 시 사용<br>- 이때 `tensor.to(device)`를 통해 텐서를 특정 위치로 이동시킬 수 있음 |
| `torch.item()` | - 텐서의 값을 파이썬 본래의 타입(int 또는 float)으로 변환해줌. 단, 1계 이상의 텐서에는 사용 불가.<br>(예외: 요소가 1개인 1계 이상의 텐서에는 사용 가능)<br>Ex.<br>```python<br>t1 = torch.ones(1,1,1,1,1,1,1)<br>t1.item() # 오류 없음```<br><br>- **item vs detach()**:<br>detach()는 텐서의 계산 그래프를 분리하여 **텐서**를 얻고자 할 때 사용하고 .item()은 단일 값을 가진 텐서에서 **Python 숫자형 값을 추출**하고자 할 때 사용함 |
| `classname.max()` | - 텐서 내 모든 요소 중 최댓값을 반환함 |
| `torch.max()` | - 기준이 되는 축을 기준으로 최댓값과 그 인덱스를 반환함 |
| `tensor.data.numpy()` | - numpy 변수로 변환하기 위해서는 `tensor.data.numpy()`를 사용함. 이때 주소를 포인트하고 있으므로 역시 값만 복사해오고 싶은 경우 `tensor.data.numpy().copy()`를 사용해야 함 |

<br>

## 2.3. 자동 미분 기능

PyTorch 및 Tensor의 가장 큰 특징

경사 계산을 위해서는 `requires_grad`를 `True`로 설정해야 함.

`requires_grad`를 통해 Define By Run 이 가능해짐 => 값을 계산해 나가며 계산 과정을 자동적으로 기록할 수 있음.

PyTorch가 합성함수의 편미분값을 자동으로 계산해줌.


### 경사 계산의 과정

1. 경사 계산용 변수(= 파라미터) 정의
2. 텐서 변수 간의 계산
3. 계산 그래프 시각화 (이해를 위해)
4. 경사 계산 = backward() 호출
5. 파라미터의 경삿값 가져오기
6. 경삿값 초기화