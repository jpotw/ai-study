7장 이하는 모두 은닉층이 존재하지 않는 machine learning model을 다룬 것이다. 사용하는 예측함수나 손실함수의 차이는 있지만 모두 하나의 선형 함수를 사용했다.

<br>

8장부터 처음으로 (예측 함수에) 은닉층이 존재하는 deep learning model을 다룬다. **두 개 이상의 선형 함수 사용**

<br>

```mermaid
flowchart LR
    inputs --> linear1[nn.Linear]
    linear1 --> relu[ReLU]
    relu --> linear2[nn.Linear]
    linear2 --> outputs
```

<br>

앞서 살펴 보았듯 선형 함수만 합성 함수로 이어주면 또다른 선형 함수가 될 뿐이다. 따라서 선형 함수에 ReLU와 같은 activation function (활성화 함수, 비선형 함수) 을 적용해야 한다.



## PyTorch에서 GPU 사용 방법

### GPU 디바이스 할당

PyTorch는 항상 디바이스를 **명시적으로 할당**해주어야 함

```python
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")
```


### GPU 사용 규칙

- 모든 텐서 변수는 GPU와 CPU 중 어디에 속하는지를 속성으로 갖고 있음
- CPU와 GPU는 `to` 메서드를 통해 서로 변환 가능
  - `tensor.to(device)`
- 모든 텐서 변수의 속성이 GPU면 GPU로 연산
- 모든 텐서 변수의 속성이 CPU면 CPU로 연산
- 다를 경우, 에러 발생
  - `RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! `

**net 인스턴스** 또한 모델 파라미터(텐서 변수)를 갖고 있기 때문에 어느 디바이스에 속하는지 신경써야 함

```python
net = Net(n_input, n_hidden, n_output).to(device)
```


cf) (데이터) 전처리: 학습 데이터를 모델에 입력하기 전에 필요에 따라 가공하는 과정

<br>

## MNIST의 입력 layer [100, 784]의 의미:

1. MNIST의 총 데이터 수는 60,000개임
2. 그러나 전체 60,000개의 데이터를 한 번에 학습하는 것은 메모리 부족 문제가 발생할 수 있음. 또 한 번의 반복 처리에 시간이 너무 많이 드는 문제가 있음.
3. 따라서 데이터를 100개씩 묶어서 학습하는 것이 일반적임. 이를 미니 배치 학습법이라고 함.
4. 이때 100개씩 묶은 데이터를 배치(batch)라고 함. batch는 데이터를 묶는 단위인 거임.
5. 784는 28x28 크기의 화소 수를 말함
6. 출력 layer [100, 10]이란, 배치 사이즈의 데이터에서 픽셀을 바탕으로 10개의 결과 중 하나로 분류하는 것을 말함(다중분류)
7. 한 epoch는 60,000개의 데이터 전부를 학습하는 것을 말함.
8. 즉 1번 ~ 100번 데이터 학습 후 101번 ~ 200번 데이터 학습 ... 이런 식으로 60,000개의 데이터를 전부 학습하는 것을 말함.
9. 그러나 똑같은 데이터를 똑같은 순서로 학습시키면 과적합(overfitting)이 발생할 수 있음.
10. 따라서 데이터를 무작위로 섞어서 학습하는 것이 일반적임. 즉 각 반복처리마다 데이터가 학습되는 양은 같지만 학습 순서(집단)는 무작위로 바뀌는 것임.

<br>

cf) 미니 배치 학습법을 사용하면 경사 하강법의 계산 결과가 local minima에 빠지는 것을 방지할 수 있음.
  - 왜 그럴까? : 무작위 선택은 확률적 특성(무작위성)을 가지므로 동일한 local minima에 빠지는 것을 방지할 수 있음. (**아직 100% 이해는 못 함**)

<br>


#### cf) 교재에 적힌 코드에서는 403 error 발생


https://github.com/pytorch/vision/issues/1938#issuecomment-797328500 참고해서 코드 수정:

```python
!wget www.di.ens.fr/~lelarge/MNIST.tar.gz
!tar -zxvf MNIST.tar.gz

from torchvision.datasets import MNIST
from torchvision import transforms

mnist_train = MNIST('./', download=False,
                    transform=transforms.Compose([
                        transforms.ToTensor(),
                    ]), train=True)
```




<br>


#### cf) Lambda Expression Playground

ex.
```python
g = lambda x: 2 * x**2 + 2
```

lambda 표현식을 사용하는 이유: 한 번 쓰이는 함수의 이름을 굳이 정할 필요 없이 간결하게 쓸 수 있기 때문.

lambda 궁금한 점:

1. if 사용이 힘들던데 만약에 복잡한 조건문을 쓸 때 어떻게 표현할 수 있는가?

   1. **삼항 연산자 사용**
   ```python
   lambda x: a if condition else b
   ```
   
   2. **and/or 연산자 사용**
   ```python
   lambda x: condition1 and value1 or value2
   ```
   
   3. **여러 조건의 경우**
   ```python
   lambda x: a if condition1 else (b if condition2 else c)
   ```

하지만 조건문이 매우 복잡한 경우, 일반 함수를 사용하는 것이 가독성이 더 좋음.


2. boolean의 경우 이런 식으로 해봤는데 맞는지 궁금함

```python
is_positive: bool = lambda x: x>0

print(is_positive(-5))
print(is_positive(10))
```

-> good