# 예측 함수 정의하기

<br>

## MNIST의 입력 layer [100, 784]의 의미:

1. MNIST의 총 데이터 수는 60,000개임
2. 그러나 전체 60,000개의 데이터를 한 번에 학습하는 것은 메모리 부족 문제가 발생할 수 있음.
3. 따라서 데이터를 100개씩 묶어서 학습하는 것이 일반적임
4. 이때 100개씩 묶은 데이터를 배치(batch)라고 함. batch는 데이터를 묶는 단위인 거임.
5. 784는 28x28 크기의 화소 수를 말함
6. 출력 layer [100, 10]이란, 배치 사이즈의 데이터에서 픽셀을 바탕으로 10개의 결과 중 하나로 분류하는 것을 말함(다중분류)
7. 한 epoch는 60,000개의 데이터 전부를 학습하는 것을 말함.
8. 즉 1번 ~ 100번 데이터 학습 후 101번 ~ 200번 데이터 학습 ... 이런 식으로 60,000개의 데이터를 전부 학습하는 것을 말함.
9. 그러나 똑같은 데이터를 똑같은 순서로 학습시키면 과적합(overfitting)이 발생할 수 있음.
10. 따라서 데이터를 무작위로 섞어서 학습하는 것이 일반적임.


<br>

예측함수에서 가장 중요한 것은 **Net**이라고 불리는 custom class로 진행된다는 것임.

Net은 쉽게 말해 input을 받고 output으로 처리하는 레이어 함수(모듈)들의 결합 (예측함수 그 자체)임.

Net은 nn.Module을 상속받은 클래스이기에 input, output은 부모 클래스의 속성을 계승하고 직접 customize해야 할 것은


1. **각 레이어 함수의 형태** (linear, relu, softmax ...)
2. **forward()의 정의** (레이어 함수들의 결합)  

이다.

<br>

## 헷갈리는 부분 정리

Net을 부를 때는 입력 차원수(n_input)와 출력 차원수(n_output)을 넣어야 함.
net을 부를 때는 입력값(inputs)을 넣어야 함.

```python
# 기본 흐름

net = Net(n_input, n_output)
outputs = net(inputs)
```